{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo large dataset processing\n",
    "\n",
    "this demo illustrate the speed of Python to open large datasets, merge and group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the earthquake data and population data from the pickle files in the data directory\n",
    "# and plot the data on a map of the world\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a csv file\n",
    "\n",
    "The file earthquake_data.csv contains 500'000 lines to dummy earthquake data between 1974 and 2023.\n",
    "\n",
    "The csv file is a text file which contains 1 line per data point:\n",
    "\n",
    "```text\n",
    "Timestamp,City,Magnitude,Depth (km)\n",
    "1974-01-01 00:00:00.000000000,Los Angeles,8.849241726842655,49.37216665723409\n",
    "1974-01-01 00:52:19.609479218,Istanbul,5.8757724072988795,24.514696519602126\n",
    "1974-01-01 01:44:39.218958437,Istanbul,3.8669320572392474,37.61128303473302\n",
    "1974-01-01 02:36:58.828437656,Kathmandu,4.844319224595527,1.3586515466092512\n",
    "1974-01-01 03:29:18.437916875,Los Angeles,6.5682598775992505,93.28988214245696\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file earthquake.csv contains  36.56 MB or raw data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print('The file earthquake.csv contains  %.2f MB or raw data' % (os.stat('../data/earthquake_data.csv').st_size/1024/1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 ms ± 21.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Test 1: load the earthquake data from the csv file\n",
    "%timeit  df = pd.read_csv('../data/earthquake_data.csv')\n",
    "\n",
    "# on my machine, this takes about 362 ms to load the data\n",
    "# 362 ms ± 24.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "# try to load the same file in Excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.8 ms ± 801 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# test 2: load the data from the pickle files\n",
    "%timeit with open('../data/earthquake_data.pkl', 'rb') as f: earthquake_data = pickle.load(f)\n",
    "\n",
    "# on my machine this takes on average 9.61 ms to load the data from a pickle file\n",
    "# 9.61 ms ± 471 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/earthquake_data.pkl', 'rb') as f: \n",
    "    earthquake_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/city_population_data.pkl', 'rb') as f:\n",
    "    population_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   Timestamp   500000 non-null  datetime64[ns]\n",
      " 1   City        500000 non-null  object        \n",
      " 2   Magnitude   500000 non-null  float64       \n",
      " 3   Depth (km)  500000 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(1)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "earthquake_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   City        7 non-null      object\n",
      " 1   Country     7 non-null      object\n",
      " 2   Population  7 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 300.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "population_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>37000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mexico City</td>\n",
       "      <td>21000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anchorage</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Istanbul</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City  Population\n",
       "0          Tokyo       37000\n",
       "1  San Francisco         883\n",
       "2    Los Angeles        3800\n",
       "3    Mexico City       21000\n",
       "4      Anchorage         290\n",
       "5       Istanbul       15000\n",
       "6      Kathmandu        1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_data[['City','Population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 ms ± 8.97 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# merge the 2 dataframes (equivalent to creating a table in excel then adding a vlookup column formula to look up the population for each city)\n",
    "%timeit combined_data = pd.merge(earthquake_data, population_data[['City','Population','Country']], on='City')\n",
    "\n",
    "# on my machine it takes on average 43.8 ms to merge the 2 datasets\n",
    "# 43.8 ms ± 2.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.merge(earthquake_data, population_data[['City','Population','Country']], on='City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 ms ± 4.63 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%timeit country_stats = combined_data.groupby('Country')['Magnitude'].agg(['median', 'mean']).round(3)\n",
    "\n",
    "# on my machine it takes on average 78 ms to calculate the median and mean magnitude for each country\n",
    "# 78 ms ± 2.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>5.998</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>5.989</td>\n",
       "      <td>5.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nepal</th>\n",
       "      <td>6.000</td>\n",
       "      <td>5.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>5.981</td>\n",
       "      <td>5.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>6.009</td>\n",
       "      <td>6.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         median   mean\n",
       "Country               \n",
       "Japan     5.998  6.000\n",
       "Mexico    5.989  5.992\n",
       "Nepal     6.000  5.998\n",
       "Turkey    5.981  5.992\n",
       "USA       6.009  6.006"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_stats = combined_data.groupby('Country')['Magnitude'].agg(['median', 'mean']).round(3)\n",
    "\n",
    "country_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
